from fastapi import FastAPI
from pydantic import BaseModel  
from fastapi.responses import JSONResponse  
import fasttext  
import os  
import re   
from openai import OpenAI  
from dotenv import load_dotenv 


# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (.env íŒŒì¼ì—ì„œ OPENAI_API_KEY ì½ì–´ì˜¤ê¸°)
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))  # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”


# FastText ëª¨ë¸ ë¡œë”©
model_path = os.path.join("models", "model_epoch_10_23th.ft")  
fasttext_model = fasttext.load_model(model_path)  


# ì´ˆì„±ìš• ê°•ì œ ì •ê·œí™” ë”•ì…”ë„ˆë¦¬
ì´ˆì„±ìš•_ëŒ€ì‘í‘œ = {
    "ã……ã…‚": "ì‹œë°œ",
    "ã…†ã…‚": "ì”¨ë°œ",
    "ã…ã…Š": "ë¯¸ì¹œ",
    "ã…‚ã……": "ë³‘ì‹ ",
    "ã…„": "ë³‘ì‹ ",
    "ã…ˆã„¹": "ì§€ë„",
    "ã„±ã……ã„²": "ê°œìƒˆë¼",
    "ã…ˆã„´": "ì¡´ë‚˜",
    "ã…ˆê°™": "ì¢†ê°™",
    "ã…ˆê¹Œ": "ì¢†ê¹Œ",
}


# í…ìŠ¤íŠ¸ ì •ê·œí™”: ì´ˆì„±ìš• ë³€í™˜ + ë¶ˆí•„ìš” ë¬¸ì ì œê±°
def normalize_text(text: str) -> str:
    text = text.strip()

    # ì´ˆì„±ìš• ì •ê·œí™”
    for ì´ˆì„±, ì¹˜í™˜ì–´ in ì´ˆì„±ìš•_ëŒ€ì‘í‘œ.items():
        text = re.sub(rf'\b{re.escape(ì´ˆì„±)}\b', ì¹˜í™˜ì–´, text)

    # ë¶ˆí•„ìš” ë¬¸ì ì œê±° (í•œê¸€, ìˆ«ì, ì˜ë¬¸, ê³µë°±ë§Œ ë‚¨ê¹€)
    text = re.sub(r"[^ê°€-í£a-zA-Z0-9\s]", "", text)

    return text


# FastText ìš•ì„¤ ê°ì§€ í•¨ìˆ˜ (ì˜¤ì§ __label__1ë§Œ badë¡œ ê°„ì£¼)
def detect_fasttext(text: str):
    cleaned_text = normalize_text(text)  # ì „ì²˜ë¦¬ ìˆ˜í–‰
    labels, probabilities = fasttext_model.predict(cleaned_text)  # ì˜ˆì¸¡ ìˆ˜í–‰
    # __label__1ì´ê³  í™•ë¥  > 0.4ì¸ ê²½ìš°ì—ë§Œ badë¡œ ê°ì§€
    detected = [label.replace("__label__", "")
                for label, prob in zip(labels, probabilities)
                if label == "__label__1" and prob > 0.4]
    return detected


# GPT-3.5ë¥¼ ì´ìš©í•œ ìš•ì„¤ ìˆœí™”(ì •ì œ) í•¨ìˆ˜
def rewrite_text_gpt3_5(text: str) -> str:
    prompt = f"""
ë‹¹ì‹ ì€ ì‚¬ëŒë“¤ì˜ ë°œí™”ë¥¼ ì •ì¤‘í•˜ê³  ê¸ì •ì ì¸ í‘œí˜„ìœ¼ë¡œ ìˆœí™”í•˜ëŠ” AIì…ë‹ˆë‹¤.

ë‹¤ìŒ ë¬¸ì¥ì„ ì•„ë˜ ì¡°ê±´ì— ë§ì¶° ìˆœí™”í•´ì£¼ì„¸ìš”:

[ğŸ’¬ ìˆœí™” ì¡°ê±´]
1. ë¬¸ì¥ì— ìš•ì„¤, ë¹„ì†ì–´, í˜ì˜¤, ì„±ì ì¸ í‘œí˜„ì´ ìˆì„ ê²½ìš° â†’ ë¬¸ë§¥ì„ ê³ ë ¤í•˜ì—¬ **ì •ì¤‘í•˜ê³  ë°”ë¥¸ í‘œí˜„**ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë°”ê¾¸ì„¸ìš”.
2. ë…¸ê³¨ì ì´ì§€ ì•Šì•„ë„ ê³µê²©ì ì´ê±°ë‚˜ ë¶€ì •ì ì¸ ë‰˜ì•™ìŠ¤ë¥¼ ê°€ì§„ ë‹¨ì–´ëŠ” **ê¸ì •ì ì´ê³  í¬ìš©ì ì¸ í‘œí˜„**ìœ¼ë¡œ ìˆœí™”í•˜ì„¸ìš”.
3. **ë¬¸ì¥ì˜ êµ¬ì¡°ì™€ ë§íˆ¬ëŠ” ìœ ì§€**í•˜ë©´ì„œ, ë¬¸ì œê°€ ë˜ëŠ” ë‹¨ì–´ë§Œ ë°”ê¾¸ëŠ” ê²ƒì´ í•µì‹¬ì…ë‹ˆë‹¤.
4. ì˜ˆì˜ ë°”ë¥´ê³  ë¶€ë“œëŸ¬ìš´ ì–´íˆ¬ë¡œ ì‘ì„±í•˜ì„¸ìš”.
5. **ìš•ì„¤ì´ ì—†ëŠ” ê²½ìš°ì—ëŠ” ë¬¸ì¥ì„ ìˆ˜ì •í•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ë°˜í™˜**í•˜ì„¸ìš”.
6. ì¶œë ¥ì€ ë°˜ë“œì‹œ **ì •ì œëœ ë¬¸ì¥ í•œ ì¤„ë§Œ**, ì„¤ëª…ì´ë‚˜ ë”°ì˜´í‘œ ì—†ì´ ì¶œë ¥í•˜ì„¸ìš”.

[ğŸ”´ ë°˜ë“œì‹œ ìˆœí™”í•´ì•¼ í•  í‘œí˜„ ì˜ˆì‹œ]
- ì´ˆì„± ìš•ì„¤ (ì˜ˆ: ã……ã…‚, ã…ˆã„¹, ã…„ ë“±)
- ê°ì • ê³¼ê²© í‘œí˜„ (ì˜ˆ: ì¡´ë‚˜, ê°œê°™ì€, ì§€ë„ ë“±)
- ì¸ì‹  ê³µê²© í‘œí˜„ (ì˜ˆ: ë¯¸ì¹œë†ˆ, ë³‘ì‹ , ìƒˆë¼, ë¸…ì‹  ë“±)

[ğŸ§  ìˆœí™” ì˜ˆì‹œ]
- "ì”¨ë°œ ì˜¤ëŠ˜ ì™œ ì´ë˜" â†’ "ì•„ ì§„ì§œ ì˜¤ëŠ˜ ì™œ ì´ë˜"
- "ê°œê°™ì€ ìƒˆë¼" â†’ "ì •ë§ ëª»ëœ ì‚¬ëŒ"
- "ì¡´ë‚˜ ì§œì¦ë‚˜" â†’ "ì •ë§ ì§œì¦ë‚˜"
- "ì§€ë„í•˜ì§€ ë§ˆ" â†’ "í™”ë‚´ì§€ ë§ˆ"
- "ë³‘ì‹ ê°™ì´ í•˜ë„¤" â†’ "ì–´ìˆ˜ë£©í•˜ê²Œ í•˜ë„¤"
- "ã……ã…‚" â†’ "ì•„ ì§„ì§œ"
- "ì €ìƒˆë¼ ë­ì•¼" â†’ "ì € ì‚¬ëŒ ë­ì§€"

ë¬¸ì¥: "{text}"
"""
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ë¬¸ì¥ì—ì„œ ë¹„ì†ì–´, ìš•ì„¤, í˜ì˜¤ í‘œí˜„ì„ ì°¾ì•„ ì •ì¤‘í•œ í‘œí˜„ìœ¼ë¡œ ìˆœí™”í•˜ëŠ” í¸ì§‘ê¸°ì•¼. ë¬¸ì¥ì˜ ë§íˆ¬ì™€ êµ¬ì¡°ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ê³ , ì„¤ëª… ì—†ì´ ê²°ê³¼ ë¬¸ì¥ë§Œ ì¶œë ¥í•´."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.5,
            max_tokens=100,
            top_p=0.9,
        )
        result = response.choices[0].message.content.strip()

        # ì–‘ìª½ ë”°ì˜´í‘œê°€ ìˆì„ ê²½ìš° ì œê±°
        if result.startswith('"') and result.endswith('"'):
            result = result[1:-1]
        return result
    except Exception as e:
        print(f"âŒ GPT ì •ì œ ì‹¤íŒ¨: {e}")
        return text


# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI()


# ìš”ì²­ ë°”ë”” ê²€ì¦ ëª¨ë¸ ì •ì˜
class TextRequest(BaseModel):
    text: str  


# ê¸°ë³¸ ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸
@app.get("/")
async def root():
    return {"message": "âœ… FastText + GPT-3.5 ìš•ì„¤ íƒì§€ ì„œë²„ ì‹¤í–‰ ì¤‘!"}


# ë¶„ì„ìš© POST ì—”ë“œí¬ì¸íŠ¸
@app.post("/analyze")
async def analyze(request: TextRequest):
    text = request.text.strip()  
    print(f"ì…ë ¥ ë¬¸ì¥: {text}")

    fasttext_result = detect_fasttext(text)  
    fasttext_hit = 1 if fasttext_result else 0  
    print(f"ğŸ” FastText íƒì§€ ê²°ê³¼: {fasttext_result}")

    # ê¸°ë³¸ ì‘ë‹µ êµ¬ì¡°
    response = {
        "fasttext": {"is_bad": fasttext_hit, "detected_words": fasttext_result},
        "result": {"original_text": text, "rewritten_text": text},
        "final_decision": 0
    }

    # FastTextê°€ badë¡œ íŒë‹¨í•œ ê²½ìš°ì—ë§Œ GPT ì •ì œ
    if fasttext_hit:
        print("âœ… FastText ìš•ì„¤ ê°ì§€ â†’ GPT ì •ì œ ì‹œì‘")
        rewritten = rewrite_text_gpt3_5(text)
        response["result"]["rewritten_text"] = rewritten
        response["final_decision"] = 1
    else:
        print("â­• í™•ë¥  ê¸°ì¤€ ë¯¸ë‹¬ë¡œ GPT ì •ì œ ì—†ì´ ì›ë¬¸ ë°˜í™˜")

    return JSONResponse(content=response)

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("fasttext_gpt:app", host="0.0.0.0", port=5000, reload=True)