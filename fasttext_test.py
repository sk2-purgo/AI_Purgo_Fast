import fasttext
import os
import re
import time
import pandas as pd
import tracemalloc
import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import confusion_matrix


# ì´ˆì„±, ë³€í˜• ìš•ì„¤ ë¦¬ìŠ¤íŠ¸
cusswords_pattern = [
    (r'ã……[\W\d_]*ã…‚', 'ì‹œë°œ'),
    (r'ì‹œ[\W\d_]*ë°œ', 'ì‹œë°œ'),
    (r'ã……[\W\d_]*ë°œ', 'ì‹œë°œ'),
    (r'ã……[\W\d_]*ë²Œ', 'ì‹œë°œ'),
    (r'ã…†[\W\d_]*ã…‚', 'ì”¨ë°œ'),
    (r'ì”¨[\W\d_]*ë°œ', 'ì”¨ë°œ'),
    (r'ã…†[\W\d_]*ë°œ', 'ì”¨ë°œ'),
    (r'ã…†[\W\d_]*ë²Œ', 'ì”¨ë°œ'),

    (r'\bã…[\W\d_]*ã…Š\b', 'ë¯¸ì¹œ'),

    (r'ã…‚[\W\d_]*ã……', 'ë³‘ì‹ '),
    (r'ë³‘[\W\d_]*ì‹ ', 'ë³‘ì‹ '),
    (r'ã…„', 'ë³‘ì‹ '),

    (r'ã…ˆ[\W\d_]*ã„¹', 'ì§€ë„'),
    (r'ã…ˆ[\W\d_]*ë„', 'ì§€ë„'),
    (r'ì§€[\W\d_]*ë„', 'ì§€ë„'),


    (r'ã…ˆ[\W\d_]*ê°™', 'ì¢†ê°™'),
    (r'ã…ˆ[\W\d_]*ë§', 'ì¢†ë§'),
    (r'ì¢†[\W\d_]*', 'ì¢†'),
    (r'ã…ˆ[\W\d_]*ê¹Œ', 'ì¢†ê¹Œ'),

    (r'ìƒ‰[\W\d_]*ë¼', 'ìƒˆë¼'),
    (r'ã„±[\W\d_]*ã……[\W\d_]*ã„²', 'ê°œìƒˆë¼'),

    (r'ì¡´[\W\d_]*ë‚˜', 'ì¡´ë‚˜'), 
    (r'ã…ˆ[\W\d_]*ã„´', 'ì¡´ë‚˜'), 
    (r'ã…—\b', 'ì‹œë°œ'),
    (r'[^ê°€-í£]ë†ˆ[^ê°€-í£]', 'ë†ˆ'),
    (r'ì”¨[\W\d_]*ë°œ[\W\d_]*ë…„', 'ì”¨ë°œë…„'),
    (r'ã…†[\W\d_]*ã…‚[\W\d_]*ã„´', 'ì”¨ë°œë…„'),
    (r'ì¢†[\W\d_]*ê°™[\W\d_]*ë…„', 'ì¢†ê°™ì€ë…„'),
]


# ì´ˆì„±, ë³€í˜• ìš•ì„¤ ë§¤í•‘ í•¨ìˆ˜
def cusswords_mapping(text):
    for pattern, replacement in cusswords_pattern:
        text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)
    return text


# ë©”ëª¨ë¦¬ ì¸¡ì • ì‹œì‘
tracemalloc.start()


# ëª¨ë¸ ë¡œë”© ì‹œê°„ ì¸¡ì •
load_start = time.time()
model_path = os.path.join("models", "model_epoch_10_23th.ft")
fasttext_model = fasttext.load_model(model_path)
load_time = time.time() - load_start


# í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í•¨ìˆ˜
def clean_text(text: str) -> str:
    text = cusswords_mapping(text) 
    return re.sub(r"[^ê°€-í£a-zA-Z0-9\s]", "", text)

# FastText ì˜ˆì¸¡ í•¨ìˆ˜
def detect_fasttext(text: str):
    cleaned_text = clean_text(text)
    start_time = time.perf_counter()
    labels, probabilities = fasttext_model.predict(cleaned_text)
    probabilities = np.asarray(probabilities)
    duration = time.perf_counter() - start_time

    if duration < 0.001:
        duration = 0.001

    detected = [label[9:] for label, prob in zip(labels, probabilities) if prob > 0.5]
    return detected, duration, list(zip(labels, probabilities))

# CSV íŒŒì¼ ë¡œë”© ë° ë¶„ì„
def analyze_csv_from_local(path: str):
    if not os.path.exists(path):
        print("âŒ CSV íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    df = pd.read_csv(path)
    if "text" not in df.columns or "label" not in df.columns:
        print("âŒ 'text' ë˜ëŠ” 'label' ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    total_infer_time = 0.0
    total_sentences = 0

    y_true = []
    y_pred = []

    with open("log/23ì°¨ last_test_2000_filtered_new í…ŒìŠ¤íŠ¸ ë¡œê·¸.txt", "w", encoding="utf-8") as f:  # ë¡œê·¸ íŒŒì¼ ì—´ê¸°
        for idx, row in df.iterrows():
            text = str(row["text"]).strip()
            true_label = str(row.get("label", "")).strip().lower()

            detected, duration, _ = detect_fasttext(text)

            # ì˜ˆì¸¡ ê²°ê³¼ ì¤‘ ì²« ë²ˆì§¸ ë¼ë²¨ì„ ì˜ˆì¸¡ê°’ìœ¼ë¡œ ì‚¬ìš© (ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)
            pred_label = detected[0].lower() if detected else ""

            y_true.append(true_label)
            y_pred.append(pred_label)

            total_infer_time += duration
            total_sentences += 1

             # ì¶œë ¥ ë‚´ìš©
            output = (
                f"ë¬¸ì¥ {idx+1}: '{text}'\n"
                f"ì˜ˆì¸¡ëœ ë ˆì´ë¸”: {detected}\n"
                f"ì¶”ë¡  ì‹œê°„: {round(duration, 4)}ì´ˆ\n"
                f"ì‹¤ì œ ë ˆì´ë¸”: {true_label}\n"
                + "-" * 50 + "\n"
            )

            print(output, end="")      
            f.write(output)           

    throughput = round(total_sentences / total_infer_time, 2) if total_infer_time > 0 else 0.0
    avg_infer_time = total_infer_time / total_sentences if total_sentences > 0 else 0.0

    # sklearnìœ¼ë¡œ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred, average='binary',pos_label='1', zero_division=0)
    recall = recall_score(y_true, y_pred, average='binary',pos_label='1', zero_division=0)
    f1 = f1_score(y_true, y_pred, average='binary',pos_label='1', zero_division=0)

    current, _ = tracemalloc.get_traced_memory()
    tracemalloc.stop()
    memory_usage_mb = current / (1024 * 1024)

    summary = {
        "ì´ ë¬¸ì¥ ìˆ˜": total_sentences,
        "Accuracy (ì •í™•ë„)": f"{accuracy:.4f}",
        "Precision (ì •ë°€ë„)": f"{precision:.4f}",
        "Recall (ì¬í˜„ìœ¨)": f"{recall:.4f}",
        "F1-score": f"{f1:.4f}",
        "í‰ê·  ì¶”ë¡  ì‹œê°„": f"{round(avg_infer_time, 4)}ì´ˆ",
        "ì „ì²´ ì¶”ë¡  ì‹œê°„": f"{round(total_infer_time, 4)}ì´ˆ",
        "ì²˜ë¦¬ëŸ‰": f"{throughput} ë¬¸ì¥/ì´ˆ",
        "ëª¨ë¸ ë¡œë”© ì‹œê°„": f"{round(load_time, 4)}ì´ˆ",
        "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰": f"{round(memory_usage_mb, 2)}MB"
    }

    print("âœ… ë¶„ì„ ìš”ì•½:")
    for k, v in summary.items():
        print(f"{k}: {v}")

    # confusion matrix ì¶”ê°€
    cm = confusion_matrix(y_true, y_pred, labels=['1', '0'])
    df_cm = pd.DataFrame(cm, index=['ì‹¤ì œ_ìš•ì„¤', 'ì‹¤ì œ_ë¹„ìš•ì„¤'], columns=['ì˜ˆì¸¡_ìš•ì„¤', 'ì˜ˆì¸¡_ë¹„ìš•ì„¤'])
    
    print("\nğŸ“Š Confusion Matrix:")
    print(df_cm)

# ì‹¤í–‰
if __name__ == "__main__":
    csv_path = "D:/ã„¹ã…‡_fasttext/data/last_test_2000_filtered_new.csv" 
    analyze_csv_from_local(csv_path)
